from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.cross_decomposition import PLSRegression
from sklearn.decomposition import PCA
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from scipy.optimize import minimize

class Model:
    def fit(self, X, Y):
        raise NotImplementedError
    
    def get_weights(self):
        raise NotImplementedError


class OLS(Model):
    def fit(self, X, Y):
        self.model = LinearRegression().fit(X, Y)

    def get_weights(self):
        return self.model.coef_


class RidgeModel(Model):
    def fit(self, X, Y, alpha=1.0):
        self.model = Ridge(alpha=alpha).fit(X, Y)

    def get_weights(self):
        return self.model.coef_


class LassoModel(Model):
    def fit(self, X, Y, alpha=0.1):
        self.model = Lasso(alpha=alpha).fit(X, Y)

    def get_weights(self):
        return self.model.coef_


class ElasticNetModel(Model):
    def fit(self, X, Y, alpha=0.1, l1_ratio=0.5):
        self.model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio).fit(X, Y)

    def get_weights(self):
        return self.model.coef_


class PCR(Model):
    def fit(self, X, Y, n_components=1):
        self.model = make_pipeline(StandardScaler(), PCA(n_components=n_components), LinearRegression()).fit(X, Y)

    def get_weights(self):
        return self.model[-1].coef_


class PLSR(Model):
    def fit(self, X, Y, n_components=1):
        self.model = PLSRegression(n_components=n_components).fit(X, Y)

    def get_weights(self):
        return self.model.coef_


class TLS(Model):
    def fit(self, X, Y):
        # Normalize the data
        X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)
        # Y = (Y - np.mean(Y)) / np.std(Y)

        # Augment the data matrix
        Z = np.column_stack((X, Y))

        # Perform SVD
        U, S, Vt = np.linalg.svd(Z, full_matrices=False)

        # The weights for the TLS solution are given by the last column of V
        # We exclude the last element because it corresponds to Y
        self.weights = Vt.T[:, -1][:-1]

        # Calculate the combined signal
        combined_signal = np.dot(X, self.weights)

        # Check for positive correlation with the target
        corr = np.corrcoef(combined_signal, Y)[0, 1]
        if corr < 0:
            # If the correlation is negative, flip the sign of the weights
            self.weights = -self.weights

    def get_weights(self):
        return self.weights

class NonNegativeLinearRegression(Model):
    def fit(self, X, Y):
        self.model = LinearRegression(positive=True).fit(X, Y)

    def get_weights(self):
        return self.model.coef_

class PositiveSumLinearRegression(Model):
    def fit(self, X, Y):
        # Define objective function: (Y - Xw)^2
        objective = lambda w: np.sum((Y - np.dot(X, w)) ** 2)
        
        # Initial guess for w is a vector of ones
        w0 = np.ones(X.shape[1])
        
        # Define the constraint: sum(w) = 1
        constraint = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}
        
        # Perform the optimization
        result = minimize(objective, w0, constraints=[constraint])
        
        # Store the optimized weights
        self.weights = result.x

    def get_weights(self):
        return self.weights

def get_model(model_name=None):
    models = {
        "ols": OLS(),
        "ridge": RidgeModel(),
        "lasso": LassoModel(),
        "elasticnet": ElasticNetModel(),
        "pcr": PCR(),
        "plsr": PLSR(),
        "tls": TLS(),
        "nonnegativelinear": NonNegativeLinearRegression(),
        "positivesumlinear": PositiveSumLinearRegression()
    }

    if model_name is None:
        return list(models.keys())
    else:
        try:
            return models[model_name.lower()]
        except KeyError:
            raise ValueError(f"Invalid model name '{model_name}'. Valid options are: {list(models.keys())}")
